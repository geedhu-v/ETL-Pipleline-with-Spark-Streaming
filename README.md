One can argue that the most challenging task in a Big Data setting is getting the data that can then be used for data analysis and predictions. 
In this project will be setting up a pipeline to ingest data from NewsAPI, clean and process it, and load it into a Spark DataFrame for analysis and predictions. 
Apache Kafka is used for data ingestion into HDFS,Spark SQL module for data analysis and Spark ML for prediction.
